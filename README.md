# Fusion-RAG
Fusion-RAG для отборочного этапа хакатона AI in Finance

Полноценная система Retrieval-Augmented Generation (RAG) со следующими возможностями:
- семантический поиск по эмбеддингам,
- текстовый поиск по TF-IDF (замена BM25),
- RRF (Reciprocal Rank Fusion) для объединённого поиска,
- масштабируемая генерация ответов с помощью LLM,
- параллельная обработка вопросов,
- батчинг эмбеддингов,
- кеширование вычислений,
- механизм checkpoint-ов и восстановления прогресса.

---

## Описание проекта

Данный скрипт реализует полный конвейер обработки вопросов с использованием RAG-подхода.  
Проект решает задачу поиска релевантной информации в базе знаний и формирование финального ответа на основе LLM модели.

Основные этапы работы:
1. Загрузка обучающих текстов.
2. Создание или загрузка эмбеддингов обучающих данных (кеширование).
3. Создание TF-IDF индекса.
4. Загрузка вопросов.
5. Создание эмбеддингов вопросов батчами.
6. Параллельная обработка вопросов:
   - поиск релевантных документов (semantic + TF-IDF + RRF),
   - формирование контекста,
   - генерация ответа,
   - сохранение прогресса.
7. Формирование итогового файла `submission.csv`.

---

## Основной функционал

### 1. Разбиение текста на чанки
Используется для поддержки длинных документов при получении эмбеддингов.

### 2. Создание эмбеддингов с батчингом
Ускоряет процесс за счёт параллелизма и уменьшения количества запросов.

### 3. Кеширование эмбеддингов обучающих данных
Повторный запуск работает значительно быстрее.

### 4. TF-IDF индекс
Лёгкая и быстрая замена BM25 для текстового поиска.

### 5. Reciprocal Rank Fusion (RRF)
Объединяет результаты семантического и TF-IDF поиска.

### 6. Параллельная обработка вопросов
Используются многопоточные вычисления (`ThreadPoolExecutor`).

### 7. Механизм надёжного выполнения
- Retry при ошибках.
- Экспоненциальная задержка.
- Сохранение прогресса.
- Checkpoint каждые N вопросов.

### 8. Генерация финальных ответов
LLM получает:
- контекст,
- вопрос,
- инструкции по стилю ответа,
- примеры идеальных ответов.

---

## Архитектура

```
train_data.csv
│
├── Предобработка:
│     ├── эмбеддинги (кеш)
│     ├── TF-IDF индекс
│
├── Вопросы:
│     ├── эмбеддинги вопросов
│     ├── параллельная обработка
│
└── Генерация ответов:
      ├── поиск релевантного контекста (RRF)
      ├── генерация ответа LLM
      ├── сохранение результатов
      └── сборка submission.csv
```

---

## Структура данных

### Входные файлы
- `train_data.csv` — база знаний (колонка `text`)
- `questions.csv` — вопросы (колонка `Вопрос`)
- `.env` — токены API:
  - `LLM_API_KEY`
  - `EMBEDDER_API_KEY`

### Выходные файлы
- `train_embeddings.pkl` — кеш эмбеддингов обучающих данных
- `progress.json` — прогресс выполнения
- `submission.csv` — финальные ответы

---

## Установка

### 1. Клонирование репозитория
```bash
git clone <URL вашего репозитория>
cd <имя_репозитория>
```

### 2. Установка зависимостей
```bash
pip install -r requirements.txt
```

### 3. Добавьте файл `.env`
```
LLM_API_KEY=ваш_ключ
EMBEDDER_API_KEY=ваш_ключ
```

---

## Запуск скрипта

```bash
python main.py
```

Скрипт автоматически:
- загрузит данные,
- создаст или загрузит кеш эмбеддингов,
- создаст TF-IDF индекс,
- обработает вопросы (параллельно),
- восстановит прогресс при повторном запуске,
- сформирует файл `submission.csv`.

---

## Основные функции

- split_text_into_chunks(text) - Разбиение текста на токенные чанки.

- create_embeddings_batch(texts) - Создание эмбеддингов батчами, обработка длинных текстов.

- load_or_create_train_embeddings() - Кеширование эмбеддингов обучающих данных.

- create_tfidf_index(texts) - Создание TF-IDF матрицы и векторизатора.

- reciprocal_rank_fusion() - Векторизованная реализация RRF.

- search_relevant_docs_optimized() - Объединённый поиск документов.

- answer_generation(question, context) - Генерация ответа LLM на основе RAG-контекста.

- process_single_question_safe() - Функция обработки одного вопроса с retry.

- load_progress(), save_progress() - Механизм восстановления выполнения.

---

## Пример пайплайна

```python
train_data = pd.read_csv('./train_data.csv')
train_embeddings = load_or_create_train_embeddings(train_data['text'])
tfidf_vectorizer, tfidf_matrix = create_tfidf_index(train_data['text'])
questions = pd.read_csv('./questions.csv')
questions_embeddings = get_questions_embeddings_batch(questions['Вопрос'])
```

---

## Особенности и преимущества

- Устойчивая работа при больших данных.
- Быстрая обработка благодаря батчингу и параллельности.
- RRF улучшает качество поиска.
- Checkpoint-ы гарантируют отсутствие потери данных при сбое.
- Поддержка длинных документов через токенные чанки.
- Гибкая и документированная архитектура.


